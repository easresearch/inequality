{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10271481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b99d4f",
   "metadata": {},
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finalized dataset \n",
    "data_2015 = pd.read_csv('dhs15_....csv')\n",
    "\n",
    "# Filter out rows where 'Gini' is greater than zero\n",
    "data_2015 = data_2015[data_2015['Gini'] > 0]\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_2015[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7']]\n",
    "y = data_2015['Gini']  # Gini is the wealth distribution\n",
    "\n",
    "# Define spatial groups (Cluster)\n",
    "spatial_groups = data_2015['GEO'].astype(int)  # Ensure spatial groups are integers\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest regressor\n",
    "rf_cv_15 = RandomForestRegressor(n_estimators=160,min_samples_split=5,max_features='sqrt',max_depth=90, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_cv_15.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = rf_cv_15.predict(X_test)\n",
    "\n",
    "# Calculate R-squared on the test set\n",
    "r_squared_test = r2_score(y_test, y_pred_test)\n",
    "print(f'R-squared on the test set: {r_squared_test:.4f}')\n",
    "\n",
    "# Calculate additional regression evaluation metrics for the test set\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "\n",
    "# Predict on the training set for the new scatter plot\n",
    "y_train_pred = rf_cv_15.predict(X_train)\n",
    "\n",
    "# Calculate R-squared on the training set\n",
    "r_squared_train = r2_score(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Predict on the full dataset\n",
    "y_pred_full = rf_cv_15.predict(X)\n",
    "\n",
    "# Calculate R-squared and MSE for the full dataset predictions\n",
    "r_squared_full = r2_score(y, y_pred_full)\n",
    "mse_full = mean_squared_error(y, y_pred_full)\n",
    "\n",
    "mae_full = np.mean(np.abs(y_pred_full - y))  # y_pred = predicted values, y = observed values\n",
    "\n",
    "# Calculate the range of the target variable\n",
    "target_range_full = y.max() - y.min()\n",
    "\n",
    "# Calculate and display MAE as a percentage of the range\n",
    "mae_percentage_of_range = (mae_full / target_range_full) * 100\n",
    "print(f'MAE as a percentage of the range full dataset: {mae_percentage_of_range:.2f}%')\n",
    "\n",
    "\n",
    "# Set the style for a cleaner look\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "# Plot feature importances for Random Forest on the training set\n",
    "fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Feature importances plot (horizontal bar plot)\n",
    "importances_rf_train = rf_cv_15.feature_importances_\n",
    "indices_rf_train = np.argsort(importances_rf_train)[::-1]\n",
    "names_rf_train = X_train.columns[indices_rf_train]\n",
    "\n",
    "# Define custom feature names (ensure they match the order of features in X_train)\n",
    "custom_feature_names = ['Nighttime Lights','Crop area','Human Footprint','NDVI','Dist. to NH','Population','Dist. to Admin Center']\n",
    "\n",
    "# Plot feature importances\n",
    "axs[0].barh(range(X_train.shape[1]), importances_rf_train[indices_rf_train], color='skyblue', align=\"center\")\n",
    "axs[0].set_yticks(range(X_train.shape[1]))\n",
    "axs[0].set_yticklabels(custom_feature_names, fontsize=18)\n",
    "axs[0].set_xlabel('Mean Decrease in Impurity', fontsize=18)\n",
    "axs[0].invert_yaxis()  # Reverse the y-axis\n",
    "# Set x-tick and y-tick labels fontsize\n",
    "for label in axs[0].get_xticklabels():\n",
    "    label.set_fontsize(12)\n",
    "\n",
    "# Scatter plot predicted vs. observed values for Random Forest on the test set\n",
    "axs[2].scatter(y, y_pred_full, alpha=0.7, edgecolors=(0, 0, 0), s=50)\n",
    "axs[2].plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=2)\n",
    "axs[2].set_xlabel('DHS 2015-16 Wealth Gini (Survey)', fontsize=14)\n",
    "axs[2].set_ylabel('Remote Sensing-based Gini (Predicted)', fontsize=13)\n",
    "axs[2].text(0.05, 0.95, f'R-squared = {r_squared_full:.2f}\\nMSE = {mse_full:.4f}',\n",
    "            transform=axs[2].transAxes, fontsize=18, verticalalignment='top')\n",
    "\n",
    "\n",
    "# Scatter plot predicted vs. observed values for Random Forest on the training set\n",
    "axs[1].scatter(y_test, y_pred_test, alpha=0.7, edgecolors=(0, 0, 0), s=50)\n",
    "axs[1].plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=2)\n",
    "axs[1].set_xlabel('DHS 2015-16 Wealth Gini (Survey)', fontsize=14)\n",
    "axs[1].set_ylabel('Remote Sensing-based Gini (Predicted)', fontsize=13)\n",
    "axs[1].text(0.05, 0.95, f'R-squared = {r_squared_test:.2f}\\nMSE = {mse_test:.4f}',\n",
    "            transform=axs[1].transAxes, fontsize=18, verticalalignment='top')\n",
    "\n",
    "# Set x-tick and y-tick labels fontsize\n",
    "for label in axs[1].get_xticklabels() + axs[1].get_yticklabels():\n",
    "    label.set_fontsize(12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf61f7",
   "metadata": {},
   "source": [
    "# Bootstrapping to estimate uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d29ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finalized dataset \n",
    "data_2015 = pd.read_csv('dhs15_....csv')\n",
    "\n",
    "# Filter out rows where 'Gini' is greater than zero\n",
    "data_2015 = data_2015[data_2015['Gini'] > 0]\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_2015[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7']]\n",
    "y = data_2015['Gini']  # Gini is the wealth distribution\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest regressor\n",
    "rf_cv_15 = RandomForestRegressor(n_estimators=160, min_samples_split=5, max_features='sqrt', max_depth=90, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_cv_15.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = rf_cv_15.predict(X_test)\n",
    "\n",
    "# Calculate R-squared on the test set\n",
    "r_squared_test = r2_score(y_test, y_pred_test)\n",
    "print(f'R-squared on the test set: {r_squared_test:.4f}')\n",
    "\n",
    "# Calculate additional regression evaluation metrics for the test set\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "# Bootstrapping to estimate uncertainty\n",
    "n_iterations = 50000  # Number of bootstrap iterations\n",
    "n_size = int(len(X_train) * 0.8)  # Size of the bootstrap sample (80% of the dataset)\n",
    "\n",
    "# Collect bootstrap predictions\n",
    "bootstrap_predictions = np.zeros((n_iterations, len(X_test)))\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Sample with replacement\n",
    "    X_train_boot, y_train_boot = resample(X_train, y_train, n_samples=n_size, random_state=i)\n",
    "    \n",
    "    # Train model on bootstrap sample\n",
    "    rf_cv_15.fit(X_train_boot, y_train_boot)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    bootstrap_predictions[i, :] = rf_cv_15.predict(X_test)\n",
    "\n",
    "# Calculate the 95% confidence intervals for the predictions\n",
    "lower_percentile = np.percentile(bootstrap_predictions, 2.5, axis=0)\n",
    "upper_percentile = np.percentile(bootstrap_predictions, 97.5, axis=0)\n",
    "\n",
    "# Calculate mean prediction and the CI\n",
    "mean_predictions = np.mean(bootstrap_predictions, axis=0)\n",
    "\n",
    "# Calculate the prediction errors\n",
    "prediction_errors = mean_predictions - y_test\n",
    "\n",
    "# Calculate the 95% CI for the errors\n",
    "lower_error = mean_predictions - lower_percentile\n",
    "upper_error = upper_percentile - mean_predictions\n",
    "\n",
    "# Print out the uncertainty analysis\n",
    "print(f'Mean MAE on Test Set: {mae_test:.4f}')\n",
    "print(f'Mean MSE on Test Set: {mse_test:.4f}')\n",
    "\n",
    "# Display the 95% CI for the prediction errors\n",
    "print(f'95% CI for prediction errors: Lower bound = {np.mean(lower_error):.4f}, Upper bound = {np.mean(upper_error):.4f}')\n",
    "\n",
    "# Visualize the uncertainty in the predictions (with CI intervals)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, mean_predictions, alpha=0.7, label='Predictions')\n",
    "plt.errorbar(y_test, mean_predictions, yerr=[lower_error, upper_error], fmt='o', color='skyblue', alpha=0.5, label='95% CI')\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('Estimated Gini (Observed)')\n",
    "plt.ylabel('Predicted Gini')\n",
    "plt.title('Predictions with 95% Confidence Intervals')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
